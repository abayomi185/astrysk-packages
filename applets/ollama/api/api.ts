/**
 * Generated by orval v6.17.0 üç∫
 * Do not edit manually.
 * Ollama REST API
 * [Ollama](https://ollama.ai/) allows you to run powerful LLM models locally on your machine, and exposes a REST API to interact with them on localhost.

Based on the [official Ollama API docs](https://github.com/jmorganca/ollama/blob/main/docs/api.md)

### Getting started

1. Download [Ollama](https://ollama.ai/)
    
2. Pull a model, following [instructions](https://github.com/jmorganca/ollama)
    
3. Fire up localhost with `ollama serve`
 * OpenAPI spec version: 1.0.0
 */
import { useQuery, useMutation } from "@tanstack/react-query";
import type {
  UseQueryOptions,
  UseMutationOptions,
  QueryFunction,
  MutationFunction,
  UseQueryResult,
  QueryKey,
} from "@tanstack/react-query";
import type {
  Generate200,
  GenerateBody,
  Create200,
  CreateBody,
  ListLocalModels200,
  ShowModel200,
  ShowModelBody,
  DeleteAModelBody,
  PullAModelBody,
  PushAModelBody,
  GenerateEmbedding200,
  GenerateEmbeddingBody,
  ChatBody,
} from "./model";
import { apiInstance, cancellableApiInstance } from "../../../api/apiInstance";
import type { ErrorType } from "../../../api/apiInstance";
import { CancelTokenSource } from "axios";

type AwaitedInput<T> = PromiseLike<T> | T;

type Awaited<O> = O extends AwaitedInput<infer T> ? T : never;

/**
 * Chat endpoint
 */
export const chat = (chatBody: ChatBody, cancelSource: CancelTokenSource) => {
  return cancellableApiInstance<Generate200>(
    {
      url: `/api/chat`,
      method: "post",
      headers: { "Content-Type": "application/json" },
      data: chatBody,
    },
    cancelSource
  );
};

export const getChatMutationOptions = <
  TError = ErrorType<unknown>,
  TContext = unknown
>(options?: {
  mutation?: UseMutationOptions<
    Awaited<ReturnType<typeof chat>>,
    TError,
    { data: ChatBody; cancelSource: CancelTokenSource },
    TContext
  >;
}) => {
  const { mutation: mutationOptions } = options ?? {};

  const mutationFn: MutationFunction<
    Awaited<ReturnType<typeof chat>>,
    { data: ChatBody; cancelSource: CancelTokenSource }
  > = (props) => {
    const { data, cancelSource } = props ?? {};

    return chat(data, cancelSource);
  };

  return { mutationFn, ...mutationOptions };
};

export type ChatMutationResult = NonNullable<Awaited<ReturnType<typeof chat>>>;
export type ChatMutationBody = ChatBody;
export type ChatMutationError = ErrorType<unknown>;

/**
 * @summary chat
 */
export const useChat = <
  TError = ErrorType<unknown>,
  TContext = unknown
>(options?: {
  mutation?: UseMutationOptions<
    Awaited<ReturnType<typeof chat>>,
    TError,
    { data: ChatBody; cancelSource: CancelTokenSource },
    TContext
  >;
}) => {
  // const mutationOptions = getChatMutationOptions({
  //   ...options,
  //   mutation: {
  //     ...options?.mutation,
  //     onMutate: async (variables) => {
  //       return { variables };
  //     },
  //   },
  // });
  const mutationOptions = getChatMutationOptions(options);

  return useMutation(mutationOptions);
};

/**
 * Generates a streamed response like shown below  
  

<img src="https://content.pstmn.io/8beb2ed9-8353-42cb-95e3-f9f5038a4e73/aW1hZ2UucG5n" alt="" height="1484" width="2552">
 * @summary generate
 */
export const generate = (generateBody: GenerateBody) => {
  return apiInstance<Generate200>({
    url: `/api/generate`,
    method: "post",
    headers: { "Content-Type": "application/json" },
    data: generateBody,
  });
};

export const getGenerateMutationOptions = <
  TError = ErrorType<unknown>,
  TContext = unknown
>(options?: {
  mutation?: UseMutationOptions<
    Awaited<ReturnType<typeof generate>>,
    TError,
    { data: GenerateBody },
    TContext
  >;
}): UseMutationOptions<
  Awaited<ReturnType<typeof generate>>,
  TError,
  { data: GenerateBody },
  TContext
> => {
  const { mutation: mutationOptions } = options ?? {};

  const mutationFn: MutationFunction<
    Awaited<ReturnType<typeof generate>>,
    { data: GenerateBody }
  > = (props) => {
    const { data } = props ?? {};

    return generate(data);
  };

  return { mutationFn, ...mutationOptions };
};

export type GenerateMutationResult = NonNullable<
  Awaited<ReturnType<typeof generate>>
>;
export type GenerateMutationBody = GenerateBody;
export type GenerateMutationError = ErrorType<unknown>;

/**
 * @summary generate
 */
export const useGenerate = <
  TError = ErrorType<unknown>,
  TContext = unknown
>(options?: {
  mutation?: UseMutationOptions<
    Awaited<ReturnType<typeof generate>>,
    TError,
    { data: GenerateBody },
    TContext
  >;
}) => {
  const mutationOptions = getGenerateMutationOptions(options);

  return useMutation(mutationOptions);
};

/**
 * Create a model from a local [Modefile](https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md)

Modelfile must be in a location `ollama` has permission to access.

A stream of JSON objects is returned. When finished, `status` is `success`.

**Parameters**

You can add `"stream": false` to the body to get a chunked rather than streamed response.

**Example Modelfile**

```
FROM llama2
# sets the temperature to 1 [higher is more creative, lower is more coherent]
PARAMETER temperature 1
# sets the context window size to 4096, this controls how many tokens the LLM can use as context to generate the next token
PARAMETER num_ctx 4096
# sets a custom system prompt to specify the behavior of the chat assistant
SYSTEM You are Mario from super mario bros, acting as an assistant.

 ```
 * @summary create
 */
export const create = (createBody: CreateBody) => {
  return apiInstance<Create200>({
    url: `/api/create`,
    method: "post",
    headers: { "Content-Type": "application/json" },
    data: createBody,
  });
};

export const getCreateMutationOptions = <
  TError = ErrorType<unknown>,
  TContext = unknown
>(options?: {
  mutation?: UseMutationOptions<
    Awaited<ReturnType<typeof create>>,
    TError,
    { data: CreateBody },
    TContext
  >;
}): UseMutationOptions<
  Awaited<ReturnType<typeof create>>,
  TError,
  { data: CreateBody },
  TContext
> => {
  const { mutation: mutationOptions } = options ?? {};

  const mutationFn: MutationFunction<
    Awaited<ReturnType<typeof create>>,
    { data: CreateBody }
  > = (props) => {
    const { data } = props ?? {};

    return create(data);
  };

  return { mutationFn, ...mutationOptions };
};

export type CreateMutationResult = NonNullable<
  Awaited<ReturnType<typeof create>>
>;
export type CreateMutationBody = CreateBody;
export type CreateMutationError = ErrorType<unknown>;

/**
 * @summary create
 */
export const useCreate = <
  TError = ErrorType<unknown>,
  TContext = unknown
>(options?: {
  mutation?: UseMutationOptions<
    Awaited<ReturnType<typeof create>>,
    TError,
    { data: CreateBody },
    TContext
  >;
}) => {
  const mutationOptions = getCreateMutationOptions(options);

  return useMutation(mutationOptions);
};

/**
 * list local models
 * @summary list local models
 */
export const listLocalModels = (signal?: AbortSignal) => {
  return apiInstance<ListLocalModels200>({
    url: `/api/tags`,
    method: "get",
    signal,
  });
};

export const getListLocalModelsQueryKey = () => [`/api/tags`] as const;

export const getListLocalModelsQueryOptions = <
  TData = Awaited<ReturnType<typeof listLocalModels>>,
  TError = ErrorType<unknown>
>(options?: {
  query?: UseQueryOptions<
    Awaited<ReturnType<typeof listLocalModels>>,
    TError,
    TData
  >;
}): UseQueryOptions<
  Awaited<ReturnType<typeof listLocalModels>>,
  TError,
  TData
> & { queryKey: QueryKey } => {
  const { query: queryOptions } = options ?? {};

  const queryKey = queryOptions?.queryKey ?? getListLocalModelsQueryKey();

  const queryFn: QueryFunction<Awaited<ReturnType<typeof listLocalModels>>> = ({
    signal,
  }) => listLocalModels(signal);

  return { queryKey, queryFn, ...queryOptions };
};

export type ListLocalModelsQueryResult = NonNullable<
  Awaited<ReturnType<typeof listLocalModels>>
>;
export type ListLocalModelsQueryError = ErrorType<unknown>;

/**
 * @summary list local models
 */
export const useListLocalModels = <
  TData = Awaited<ReturnType<typeof listLocalModels>>,
  TError = ErrorType<unknown>
>(options?: {
  query?: UseQueryOptions<
    Awaited<ReturnType<typeof listLocalModels>>,
    TError,
    TData
  >;
}): UseQueryResult<TData, TError> & { queryKey: QueryKey } => {
  const queryOptions = getListLocalModelsQueryOptions(options);

  const query = useQuery(queryOptions) as UseQueryResult<TData, TError> & {
    queryKey: QueryKey;
  };

  query.queryKey = queryOptions.queryKey;

  return query;
};

/**
 * show model
 * @summary show model
 */
export const showModel = (showModelBody: ShowModelBody) => {
  return apiInstance<ShowModel200>({
    url: `/api/show`,
    method: "post",
    headers: { "Content-Type": "application/json" },
    data: showModelBody,
  });
};

export const getShowModelMutationOptions = <
  TError = ErrorType<unknown>,
  TContext = unknown
>(options?: {
  mutation?: UseMutationOptions<
    Awaited<ReturnType<typeof showModel>>,
    TError,
    { data: ShowModelBody },
    TContext
  >;
}): UseMutationOptions<
  Awaited<ReturnType<typeof showModel>>,
  TError,
  { data: ShowModelBody },
  TContext
> => {
  const { mutation: mutationOptions } = options ?? {};

  const mutationFn: MutationFunction<
    Awaited<ReturnType<typeof showModel>>,
    { data: ShowModelBody }
  > = (props) => {
    const { data } = props ?? {};

    return showModel(data);
  };

  return { mutationFn, ...mutationOptions };
};

export type ShowModelMutationResult = NonNullable<
  Awaited<ReturnType<typeof showModel>>
>;
export type ShowModelMutationBody = ShowModelBody;
export type ShowModelMutationError = ErrorType<unknown>;

/**
 * @summary show model
 */
export const useShowModel = <
  TError = ErrorType<unknown>,
  TContext = unknown
>(options?: {
  mutation?: UseMutationOptions<
    Awaited<ReturnType<typeof showModel>>,
    TError,
    { data: ShowModelBody },
    TContext
  >;
}) => {
  const mutationOptions = getShowModelMutationOptions(options);

  return useMutation(mutationOptions);
};

/**
 * delete a model
 * @summary delete a model
 */
export const deleteAModel = (deleteAModelBody: DeleteAModelBody) => {
  return apiInstance<unknown>({
    url: `/api/delete`,
    method: "delete",
    headers: { "Content-Type": "application/json" },
    data: deleteAModelBody,
  });
};

export const getDeleteAModelMutationOptions = <
  TError = ErrorType<unknown>,
  TContext = unknown
>(options?: {
  mutation?: UseMutationOptions<
    Awaited<ReturnType<typeof deleteAModel>>,
    TError,
    { data: DeleteAModelBody },
    TContext
  >;
}): UseMutationOptions<
  Awaited<ReturnType<typeof deleteAModel>>,
  TError,
  { data: DeleteAModelBody },
  TContext
> => {
  const { mutation: mutationOptions } = options ?? {};

  const mutationFn: MutationFunction<
    Awaited<ReturnType<typeof deleteAModel>>,
    { data: DeleteAModelBody }
  > = (props) => {
    const { data } = props ?? {};

    return deleteAModel(data);
  };

  return { mutationFn, ...mutationOptions };
};

export type DeleteAModelMutationResult = NonNullable<
  Awaited<ReturnType<typeof deleteAModel>>
>;
export type DeleteAModelMutationBody = DeleteAModelBody;
export type DeleteAModelMutationError = ErrorType<unknown>;

/**
 * @summary delete a model
 */
export const useDeleteAModel = <
  TError = ErrorType<unknown>,
  TContext = unknown
>(options?: {
  mutation?: UseMutationOptions<
    Awaited<ReturnType<typeof deleteAModel>>,
    TError,
    { data: DeleteAModelBody },
    TContext
  >;
}) => {
  const mutationOptions = getDeleteAModelMutationOptions(options);

  return useMutation(mutationOptions);
};

/**
 * Pull a model from the [Ollama library](https://ollama.ai/library)

**Parameters**

You can add `"stream": false` to the body to get a chunked response instead of streamed
 * @summary pull a model
 */
export const pullAModel = (pullAModelBody: PullAModelBody) => {
  return apiInstance<unknown>({
    url: `/api/pull`,
    method: "post",
    headers: { "Content-Type": "application/json" },
    data: pullAModelBody,
  });
};

export const getPullAModelMutationOptions = <
  TError = ErrorType<unknown>,
  TContext = unknown
>(options?: {
  mutation?: UseMutationOptions<
    Awaited<ReturnType<typeof pullAModel>>,
    TError,
    { data: PullAModelBody },
    TContext
  >;
}): UseMutationOptions<
  Awaited<ReturnType<typeof pullAModel>>,
  TError,
  { data: PullAModelBody },
  TContext
> => {
  const { mutation: mutationOptions } = options ?? {};

  const mutationFn: MutationFunction<
    Awaited<ReturnType<typeof pullAModel>>,
    { data: PullAModelBody }
  > = (props) => {
    const { data } = props ?? {};

    return pullAModel(data);
  };

  return { mutationFn, ...mutationOptions };
};

export type PullAModelMutationResult = NonNullable<
  Awaited<ReturnType<typeof pullAModel>>
>;
export type PullAModelMutationBody = PullAModelBody;
export type PullAModelMutationError = ErrorType<unknown>;

/**
 * @summary pull a model
 */
export const usePullAModel = <
  TError = ErrorType<unknown>,
  TContext = unknown
>(options?: {
  mutation?: UseMutationOptions<
    Awaited<ReturnType<typeof pullAModel>>,
    TError,
    { data: PullAModelBody },
    TContext
  >;
}) => {
  const mutationOptions = getPullAModelMutationOptions(options);

  return useMutation(mutationOptions);
};

/**
 * Upload a model to a model library. Requires registering for ollama.ai and adding a public key first.
 * @summary push a model
 */
export const pushAModel = (pushAModelBody: PushAModelBody) => {
  return apiInstance<void>({
    url: `/api/push`,
    method: "post",
    headers: { "Content-Type": "application/json" },
    data: pushAModelBody,
  });
};

export const getPushAModelMutationOptions = <
  TError = ErrorType<unknown>,
  TContext = unknown
>(options?: {
  mutation?: UseMutationOptions<
    Awaited<ReturnType<typeof pushAModel>>,
    TError,
    { data: PushAModelBody },
    TContext
  >;
}): UseMutationOptions<
  Awaited<ReturnType<typeof pushAModel>>,
  TError,
  { data: PushAModelBody },
  TContext
> => {
  const { mutation: mutationOptions } = options ?? {};

  const mutationFn: MutationFunction<
    Awaited<ReturnType<typeof pushAModel>>,
    { data: PushAModelBody }
  > = (props) => {
    const { data } = props ?? {};

    return pushAModel(data);
  };

  return { mutationFn, ...mutationOptions };
};

export type PushAModelMutationResult = NonNullable<
  Awaited<ReturnType<typeof pushAModel>>
>;
export type PushAModelMutationBody = PushAModelBody;
export type PushAModelMutationError = ErrorType<unknown>;

/**
 * @summary push a model
 */
export const usePushAModel = <
  TError = ErrorType<unknown>,
  TContext = unknown
>(options?: {
  mutation?: UseMutationOptions<
    Awaited<ReturnType<typeof pushAModel>>,
    TError,
    { data: PushAModelBody },
    TContext
  >;
}) => {
  const mutationOptions = getPushAModelMutationOptions(options);

  return useMutation(mutationOptions);
};

/**
 * In LLMs, embeddings are numerical representations of words, phrases, or sentences that capture their meaning and context

### Parameters

- `model`: name of model to generate embeddings from
- `prompt`: text to generate embeddings for
    

Advanced parameters:

- `options`: additional model parameters listed in the documentation for the [Modelfile](https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md#valid-parameters-and-values) such as `temperature`
 * @summary generate embedding
 */
export const generateEmbedding = (
  generateEmbeddingBody: GenerateEmbeddingBody
) => {
  return apiInstance<GenerateEmbedding200>({
    url: `/api/embeddings`,
    method: "post",
    headers: { "Content-Type": "application/json" },
    data: generateEmbeddingBody,
  });
};

export const getGenerateEmbeddingMutationOptions = <
  TError = ErrorType<unknown>,
  TContext = unknown
>(options?: {
  mutation?: UseMutationOptions<
    Awaited<ReturnType<typeof generateEmbedding>>,
    TError,
    { data: GenerateEmbeddingBody },
    TContext
  >;
}): UseMutationOptions<
  Awaited<ReturnType<typeof generateEmbedding>>,
  TError,
  { data: GenerateEmbeddingBody },
  TContext
> => {
  const { mutation: mutationOptions } = options ?? {};

  const mutationFn: MutationFunction<
    Awaited<ReturnType<typeof generateEmbedding>>,
    { data: GenerateEmbeddingBody }
  > = (props) => {
    const { data } = props ?? {};

    return generateEmbedding(data);
  };

  return { mutationFn, ...mutationOptions };
};

export type GenerateEmbeddingMutationResult = NonNullable<
  Awaited<ReturnType<typeof generateEmbedding>>
>;
export type GenerateEmbeddingMutationBody = GenerateEmbeddingBody;
export type GenerateEmbeddingMutationError = ErrorType<unknown>;

/**
 * @summary generate embedding
 */
export const useGenerateEmbedding = <
  TError = ErrorType<unknown>,
  TContext = unknown
>(options?: {
  mutation?: UseMutationOptions<
    Awaited<ReturnType<typeof generateEmbedding>>,
    TError,
    { data: GenerateEmbeddingBody },
    TContext
  >;
}) => {
  const mutationOptions = getGenerateEmbeddingMutationOptions(options);

  return useMutation(mutationOptions);
};
